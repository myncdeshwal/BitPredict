{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bitPredict.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "qk48zOuj1W0o",
        "WQRYaoFhtCPe",
        "NG9xLafMxto9",
        "r3wDFkDL049F",
        "H5Wa-FImPqBi",
        "phBG6_4joxSA",
        "Xi9C35gbJgnq",
        "fq58xpYOwFfu",
        "B_SAee0UDQKo",
        "8D_IEnjiBabr",
        "AR2Y-_UAqmu1",
        "rGM3Iw-LBhTL",
        "wG8B5U3BORSC",
        "yk-OIvdvditV",
        "vpT27NWYgAi-",
        "zEV1MCNhEozI"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Imports "
      ],
      "metadata": {
        "id": "qk48zOuj1W0o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0FzH_N1w0LPH"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import common_functions as cf\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras import layers \n",
        "import tensorflow_datasets as tfds\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import csv\n",
        "import os \n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import sklearn "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(range(10,1-1))"
      ],
      "metadata": {
        "id": "KhV3m9v7dzyL",
        "outputId": "03f8f7cd-8bef-4304-f5e1-161f044a40ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting data with pandas"
      ],
      "metadata": {
        "id": "6zzb43cN2zxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/BTC_USD_2013-10-01_2021-05-18-CoinDesk.csv"
      ],
      "metadata": {
        "id": "lA75rzDz2193",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46d8bc4f-cf8a-43ed-d723-a9942cc62ab7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-07 15:58:25--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/BTC_USD_2013-10-01_2021-05-18-CoinDesk.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 178509 (174K) [text/plain]\n",
            "Saving to: ‘BTC_USD_2013-10-01_2021-05-18-CoinDesk.csv’\n",
            "\n",
            "\r          BTC_USD_2   0%[                    ]       0  --.-KB/s               \rBTC_USD_2013-10-01_ 100%[===================>] 174.33K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2022-06-07 15:58:25 (10.8 MB/s) - ‘BTC_USD_2013-10-01_2021-05-18-CoinDesk.csv’ saved [178509/178509]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_df = pd.read_csv(\"BTC_USD_2013-10-01_2021-05-18-CoinDesk.csv\", \n",
        "                     parse_dates = [\"Date\"],\n",
        "                     index_col = [\"Date\"])\n",
        "bitcoin_prices_df = pd.DataFrame(csv_df[\"Closing Price (USD)\"]).rename(columns = {\"Closing Price (USD)\": \"price\"})\n",
        "bitcoin_prices_df.plot()"
      ],
      "metadata": {
        "id": "dEXWTkgs2289",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "8b83da6c-da1f-4112-87c8-3334027dd199"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc7d7c7e990>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting Data with python"
      ],
      "metadata": {
        "id": "WQRYaoFhtCPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/BTC_USD_2013-10-01_2021-05-18-CoinDesk.csv"
      ],
      "metadata": {
        "id": "LVVSmRMjy3dC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ab77483-5972-4356-c60d-755f5223f1b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-07 12:30:43--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/BTC_USD_2013-10-01_2021-05-18-CoinDesk.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 178509 (174K) [text/plain]\n",
            "Saving to: ‘BTC_USD_2013-10-01_2021-05-18-CoinDesk.csv.1’\n",
            "\n",
            "\r          BTC_USD_2   0%[                    ]       0  --.-KB/s               \rBTC_USD_2013-10-01_ 100%[===================>] 174.33K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2022-06-07 12:30:43 (7.71 MB/s) - ‘BTC_USD_2013-10-01_2021-05-18-CoinDesk.csv.1’ saved [178509/178509]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "timesteps = []\n",
        "btc_price = []\n",
        "\n",
        "with open(\"/content/BTC_USD_2013-10-01_2021-05-18-CoinDesk.csv\") as f:\n",
        "  csv_reader = csv.reader(f, delimiter = \",\")\n",
        "  next(csv_reader) #skip first line which contains column names and no data\n",
        "  for line in csv_reader:\n",
        "    timesteps.append(datetime.strptime(line[1], \"%Y-%m-%d\"))\n",
        "    btc_price.append(float(line[2]))\n"
      ],
      "metadata": {
        "id": "hmM1_3PrtFB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Training and test Data (for evaluation purposes)"
      ],
      "metadata": {
        "id": "NG9xLafMxto9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split_size = int(0.8 * len(bitcoin_prices_df))\n",
        "\n",
        "train_df = bitcoin_prices_df[:split_size]\n",
        "test_df = bitcoin_prices_df[split_size:]\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "cf.plot_time_series(test_df.index, test_df[\"price\"], format ='-', label = \"test\")\n",
        "cf.plot_time_series(train_df.index, train_df[\"price\"], format ='-', label = \"train\")\n",
        "\n",
        "X_train , y_train = train_df.index.to_numpy(), train_df[\"price\"].to_numpy(), \n",
        "X_val , y_val  = test_df.index.to_numpy(), test_df[\"price\"].to_numpy()"
      ],
      "metadata": {
        "id": "M575iL4TxwmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Naive Model and MASE and other errors\n"
      ],
      "metadata": {
        "id": "r3wDFkDL049F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_naive_preds = bitcoin_prices_df[:-1][\"price\"].to_numpy()\n",
        "plt.figure(figsize=(10,7))"
      ],
      "metadata": {
        "id": "pWbCcwqV1G1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8a5a5c9-00d0-4fae-8a0f-668b4bdc8263"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 0 Axes>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mase_time_series(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  assuming no seasonality of data\n",
        "  \"\"\"\n",
        "\n",
        "  mae = tf.reduce_mean(tf.abs(y_true-y_pred))\n",
        "  mae_naive = tf.reduce_mean(tf.abs(y_true[1:]-y_true[:-1]))\n",
        "  \n",
        "  return mae/mae_naive\n",
        "\n",
        "def evaluate_time_series(y_true, y_pred):\n",
        "  \n",
        "  y_true = tf.cast(y_true, dtype=tf.float32)\n",
        "  y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
        "  \n",
        "  mase = mase_time_series(y_true, y_pred)\n",
        "  mae = keras.metrics.mean_absolute_error(y_true, y_pred)\n",
        "  mse = keras.metrics.mean_squared_error(y_true, y_pred)\n",
        "  rmse = tf.sqrt(mse)\n",
        "  mape = keras.metrics.mean_absolute_percentage_error(y_true, y_pred)\n",
        "  return {\"mae\": mae.numpy(), \"mse\":mse.numpy(), \"rmse\":rmse.numpy(), \"mape\":mape.numpy(), \"mase\":mase.numpy()}\n",
        "\n",
        "naive_results = evaluate_time_series(y_val[1:] ,y_naive_preds[split_size:])"
      ],
      "metadata": {
        "id": "o5_TGN4A2Rip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data into Windows and horizons wihtout tf"
      ],
      "metadata": {
        "id": "H5Wa-FImPqBi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_labelled_windows(x, window_size , horizon):\n",
        "  \"\"\"\n",
        "  creates labels for windowed dataset\n",
        "  [0...7] -> ([0...6],[7])\n",
        "  \"\"\"\n",
        "\n",
        "  return x[:, :-horizon], x[:, -horizon:]\n",
        "\n",
        "def make_windows(x, window_size, horizon):\n",
        "\n",
        "  window_step = np.expand_dims(np.arange(window_size+horizon), axis = 0) \n",
        "  window_indexes = window_step + np.expand_dims(np.arange(len(x)-(window_size+horizon-1)), axis=0).T\n",
        "  windowed_array = x[window_indexes]\n",
        "  return get_labelled_windows(windowed_array,window_size,horizon) \n"
      ],
      "metadata": {
        "id": "1iaopg1n9g0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting data (shapefix) from tf datasets"
      ],
      "metadata": {
        "id": "phBG6_4joxSA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This function only does the windows horizon array has to be passed itself \n",
        "windows_dataset = keras.utils.timeseries_dataset_from_array(tf.cast(bitcoin_prices_df[\"price\"].to_numpy(), dtype=tf.float32),\n",
        "                                                            tf.cast(bitcoin_prices_df[\"price\"].to_numpy()[7:], dtype=tf.float32 ),\n",
        "                                                            sequence_length=7, batch_size=None)\n",
        "\n",
        "train_ds = windows_dataset.take(split_size)\n",
        "val_ds = windows_dataset.skip(len(train_ds))"
      ],
      "metadata": {
        "id": "KyWQ8YhEpZkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "                                            # (this one might destory the ram)\n",
        "train_windows, train_labels = tuple(zip(*train_ds))\n",
        "train_windows = tf.squeeze(train_windows)\n",
        "train_labels = tf.squeeze(train_labels)\n",
        "train_ds = tf.data.Dataset.from_tensor_slices( (train_windows, train_labels) )\n",
        "\n",
        "val_windows, val_labels = tuple(zip(*val_ds))\n",
        "val_windows = tf.squeeze(val_windows)\n",
        "val_labels = tf.squeeze(val_labels)\n",
        "val_ds = tf.data.Dataset.from_tensor_slices( (val_windows, val_labels) )\n",
        "\n",
        "train_ds  = train_ds.batch(128)\n",
        "val_ds = val_ds.batch(128)"
      ],
      "metadata": {
        "id": "QoOXng12Y59q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "                                                  #mothod 2\n",
        "train_windows = [] \n",
        "train_labels = []\n",
        "\n",
        "for window, label in train_ds.unbatch().take(-1):  # only take first element of dataset\n",
        "    train_windows.append(window)\n",
        "    train_labels.append(label)\n",
        "\n",
        "#tensorflow is chill with numpy arrays, cant handle lists or dictonaries\n",
        "\n",
        "train_windows = np.array(train_windows)\n",
        "train_labels = np.array(train_labels)\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices( (train_windows, train_labels) )\n",
        "train_ds  = train_ds.batch(128)\n",
        "\n",
        "val_windows = [] \n",
        "val_labels = []\n",
        "\n",
        "for window, label in val_ds.unbatch().take(-1):  # only take first element of dataset\n",
        "    val_windows.append(window)\n",
        "    val_labels.append(label)\n",
        "\n",
        "#tensorflow is chill with numpy arrays, cant handle lists or dictonaries\n",
        "\n",
        "val_windows = np.array(val_windows)\n",
        "val_labels = np.array(val_labels)\n",
        "\n",
        "val_ds = tf.data.Dataset.from_tensor_slices( (val_windows, val_labels) )\n",
        "val_ds  = val_ds.batch(128)"
      ],
      "metadata": {
        "id": "vCiZizc3mYRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model 1 Dense"
      ],
      "metadata": {
        "id": "Xi9C35gbJgnq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "model_1 = keras.Sequential([\n",
        "                            layers.Dense(128, activation = \"relu\"),\n",
        "                            layers.Dense(1, activation = \"linear\")\n",
        "])\n",
        "\n",
        "model_1.compile(loss=\"mae\", optimizer=keras.optimizers.Adam(learning_rate=.001), metrics = [\"mae\",\"mse\"])\n",
        "\n",
        "model_1_history = model_1.fit(train_ds, epochs = 150, validation_data = val_ds)\n"
      ],
      "metadata": {
        "id": "yyINyNHdJjcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_pred = model_1.predict(val_ds)\n",
        "model_1_results = evaluate_time_series(tf.squeeze(val_labels), tf.squeeze(val_pred))\n",
        "pd.DataFrame(model_1_history.history).plot()\n",
        "plt.figure(figsize=(10,7))\n",
        "cf.plot_time_series(X_val[-len(val_labels):], val_labels, format=\"-\", start=450, label=\"val_data\")\n",
        "cf.plot_time_series(X_val[-len(val_labels):], tf.squeeze(val_pred), format=\"-\", start=450, label=\"predictions\")"
      ],
      "metadata": {
        "id": "eWFT3q2jtvuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 2 window_size=30"
      ],
      "metadata": {
        "id": "fq58xpYOwFfu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This function only does the windows horizon array has to be passed itself \n",
        "\n",
        "windows_dataset = keras.utils.timeseries_dataset_from_array(tf.cast(bitcoin_prices_df[\"price\"].to_numpy(), dtype=tf.float32),\n",
        "                                                            tf.cast(bitcoin_prices_df[\"price\"].to_numpy()[30:], dtype=tf.float32 ),\n",
        "                                                            sequence_length=30, batch_size=None)\n",
        "\n",
        "train_ds = windows_dataset.take(split_size)\n",
        "val_ds = windows_dataset.skip(len(train_ds))\n",
        "\n",
        "\n",
        "                                            # (this one might destory the ram)\n",
        "train_windows, train_labels = tuple(zip(*train_ds))\n",
        "train_windows = tf.squeeze(train_windows)\n",
        "train_labels = tf.squeeze(train_labels)\n",
        "train_ds = tf.data.Dataset.from_tensor_slices( (train_windows, train_labels) )\n",
        "\n",
        "val_windows, val_labels = tuple(zip(*val_ds))\n",
        "val_windows = tf.squeeze(val_windows)\n",
        "val_labels = tf.squeeze(val_labels)\n",
        "val_ds = tf.data.Dataset.from_tensor_slices( (val_windows, val_labels) )\n",
        "\n",
        "train_ds  = train_ds.batch(128)\n",
        "val_ds = val_ds.batch(128)"
      ],
      "metadata": {
        "id": "1GFU5HbTwI-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "model_2 = keras.Sequential([\n",
        "                            layers.Dense(128, activation = \"relu\"),\n",
        "                            layers.Dense(HORIZON, activation = \"linear\")\n",
        "])\n",
        "\n",
        "model_2.compile(loss=\"mae\", optimizer=keras.optimizers.Adam(learning_rate=.001), metrics = [\"mae\",\"mse\"])\n",
        "\n",
        "model_2_history = model_2.fit(train_ds, epochs = 150, validation_data = val_ds)"
      ],
      "metadata": {
        "id": "pzUywSVRwUx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_pred = model_2.predict(val_ds)\n",
        "model_2_results = evaluate_time_series(tf.squeeze(val_labels), tf.squeeze(val_pred))\n",
        "pd.DataFrame(model_2_history.history).plot()\n",
        "plt.figure(figsize=(10,7))\n",
        "hf.plot_time_series(X_val[-len(val_labels):], val_labels, format=\"-\", start=450, label=\"val_data\")\n",
        "hf.plot_time_series(X_val[-len(val_labels):], tf.squeeze(val_pred), format=\"-\", start=450, label=\"predictions\")\n",
        "model_2_results"
      ],
      "metadata": {
        "id": "1OgeExavwZss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 3 W=30 H=7"
      ],
      "metadata": {
        "id": "B_SAee0UDQKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HORIZON = 7\n",
        "WINDOW_SIZE = 30 \n",
        "windows , labels = make_windows(bitcoin_prices_df[\"price\"].to_numpy(), window_size=30, horizon=7)\n",
        "train_windows = tf.cast(windows[:split_size], dtype=tf.float32)\n",
        "train_labels = tf.cast(labels[:split_size], dtype=tf.float32)\n",
        "val_windows= tf.cast(windows[split_size:], dtype=tf.float32)\n",
        "val_labels = tf.cast(labels[split_size:], dtype=tf.float32)\n",
        "tf.random.set_seed(42)\n",
        "model_3 = keras.Sequential([\n",
        "                            layers.Dense(128, activation = \"relu\"),\n",
        "                            layers.Dense(7, activation = \"linear\")\n",
        "])\n",
        "model_3.compile(loss=\"mae\", optimizer=keras.optimizers.Adam(learning_rate=.001), metrics = [\"mae\",\"mse\"])\n",
        "\n",
        "model_3_history = model_3.fit(train_windows, train_labels, epochs = 150,\n",
        "                              validation_data = (val_windows,val_labels), batch_size = 128,\n",
        "                              callbacks=[cf.create_model_checkpoint(\"model_3\", onlyWeights=True)])\n",
        "\n",
        "model_3.load_weights(\"/content/model_experiments/model_3\")\n",
        "\n",
        "cf.plot_loss_curves(model_3_history, plot_accuracy=False)\n",
        "model_3_results= cf.evaluate_time_series(val_labels, model_3.predict(val_windows))\n",
        "\n",
        "cf.plot_time_series(X_val[-len(val_labels):], tf.reduce_mean(val_labels, axis=1), format=\"-\", label=\"actual\")\n",
        "cf.plot_time_series(X_val[-len(val_labels):], tf.reduce_mean(model_3.predict(val_windows), axis=1), format=\"-\",  label=\"pred\")"
      ],
      "metadata": {
        "id": "gyo_XEBtF6WV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BYEqruewhtZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 4 Conv1D W=7 H=1"
      ],
      "metadata": {
        "id": "8D_IEnjiBabr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HORIZON = 1\n",
        "WINDOW_SIZE = 7\n",
        "windows ,labels = make_windows(bitcoin_prices_df[\"price\"].to_numpy(), 7, 1)\n",
        "\n",
        "train_labels  = tf.cast(labels[:split_size], dtype=tf.float32) \n",
        "val_labels    = tf.cast(labels[split_size:], dtype=tf.float32) \n",
        "train_windows = tf.cast(windows[:split_size], dtype=tf.float32)\n",
        "val_windows   = tf.cast(windows[split_size:], dtype=tf.float32)\n",
        "\n",
        "model_4 = keras.Sequential([\n",
        "    layers.Lambda(lambda x: tf.expand_dims(x, axis=1)),\n",
        "    layers.Conv1D(128, kernel_size=5, padding='causal', activation=\"relu\"),\n",
        "    layers.Dense(2, activation=\"linear\")\n",
        "])\n",
        "\n",
        "model_4.compile(loss=\"mae\", optimizer=\"Adam\", metrics=[\"mae\", \"mse\"])\n",
        "\n",
        "model_4_history = model_4.fit(train_windows, train_labels, epochs = 150,\n",
        "                              validation_data = (val_windows,val_labels), batch_size = 128,\n",
        "                              callbacks=[cf.create_model_checkpoint(\"model_4\", onlyWeights=True)],\n",
        "                              verbose = 1)\n",
        "\n",
        "model_4.load_weights(\"/content/model_experiments/model_4\")\n",
        "\n",
        "cf.plot_loss_curves(model_4_history, plot_accuracy=False)\n",
        "model_4.evaluate(val_windows, val_labels)\n",
        "model_4_results= cf.evaluate_time_series(val_labels, model_4.predict(val_windows))\n",
        "model_4.summary()"
      ],
      "metadata": {
        "id": "tJAC2D8IZ6cS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model 5 RNN W=7 H=1"
      ],
      "metadata": {
        "id": "AR2Y-_UAqmu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HORIZON = 1\n",
        "WINDOW_SIZE = 7\n",
        "windows ,labels = make_windows(bitcoin_prices_df[\"price\"].to_numpy(), 7, 1)\n",
        "\n",
        "train_labels  = tf.cast(labels[:split_size], dtype=tf.float32) \n",
        "val_labels    = tf.cast(labels[split_size:], dtype=tf.float32) \n",
        "train_windows = tf.cast(windows[:split_size], dtype=tf.float32)\n",
        "val_windows   = tf.cast(windows[split_size:], dtype=tf.float32)\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "inputs = layers.Input(shape = (7))\n",
        "x = layers.Lambda(lambda x : tf.expand_dims(x, axis=1)) (inputs)\n",
        "x = layers.LSTM(128, activation=\"relu\") (x)\n",
        "outputs = layers.Dense(HORIZON)(x)\n",
        "\n",
        "model_5 = keras.Model(inputs, outputs)\n",
        "\n",
        "model_5.compile(loss=\"mae\", optimizer = \"Adam\")\n",
        "\n",
        "model_5_history = model_5.fit(train_windows, train_labels, epochs = 150,\n",
        "                              validation_data = (val_windows,val_labels), batch_size = 128,\n",
        "                              callbacks=[cf.create_model_checkpoint(\"model_5\", onlyWeights=True)],\n",
        "                              verbose = 1)\n",
        "model_5.load_weights(\"model_experiments/model_5\")\n",
        "model_5.evaluate(val_windows,val_labels)\n",
        "model_5_results = cf.evaluate_time_series(val_labels, model_5.predict(val_windows))"
      ],
      "metadata": {
        "id": "KlErJXqDqtLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing Multivariate data"
      ],
      "metadata": {
        "id": "AchULQel8vZ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HORIZON = 1\n",
        "WINDOW_SIZE = 7\n",
        "\n",
        "block_reward_1 = 50 # 3 January 2009 - this block reward isn't in our dataset (our data starts from 01 October 2013)\n",
        "block_reward_2 = 25 # 8 November 2012\n",
        "block_reward_3 = 12.5 # 9 July 2016\n",
        "block_reward_4 = 6.25 # 18 May 2020\n",
        "\n",
        "# Block reward dates\n",
        "block_reward_2_datetime = np.datetime64(\"2012-11-28\")\n",
        "block_reward_3_datetime = np.datetime64(\"2016-07-09\")\n",
        "block_reward_4_datetime = np.datetime64(\"2020-05-18\")\n",
        "\n",
        "block_reward_2_days = (block_reward_3_datetime - bitcoin_prices_df.index[0]).days\n",
        "block_reward_3_days = (block_reward_4_datetime - bitcoin_prices_df.index[0]).days\n",
        "\n",
        "multivariate_df = bitcoin_prices_df.copy()\n",
        "multivariate_df[\"block_reward\"] = None\n",
        "multivariate_df.iloc[:block_reward_2_days, -1] =  block_reward_2\n",
        "multivariate_df.iloc[block_reward_2_days:block_reward_3_days , -1] =  block_reward_3\n",
        "multivariate_df.iloc[block_reward_3_days:, -1] =  block_reward_4\n",
        "\n",
        "pd.DataFrame(sklearn.preprocessing.minmax_scale(multivariate_df[[\"price\", \"block_reward\"]]),\n",
        "                                                                       columns=multivariate_df.columns,\n",
        "                                                                       index=multivariate_df.index).plot()\n",
        "\n",
        "for i in range(WINDOW_SIZE):\n",
        "  multivariate_df[f\"price{i+1}\"] = multivariate_df[\"price\"].shift(periods = i+1)\n",
        "\n",
        "multivariate_df = multivariate_df.dropna()\n",
        "y = multivariate_df[\"price\"].to_numpy()\n",
        "X = multivariate_df.drop(\"price\", axis = 1).astype(np.float32)\n",
        "\n",
        "X_train, X_val = X[:split_size], X[split_size:]\n",
        "y_train, y_val = y[:split_size], y[split_size:]"
      ],
      "metadata": {
        "id": "suFA4hTg9OIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 6 Dense multivariate W=7 H=1"
      ],
      "metadata": {
        "id": "rGM3Iw-LBhTL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "model_6 = keras.Sequential([\n",
        "                            layers.Dense(128, activation = \"relu\"),\n",
        "                            layers.Dense(64, activation = \"relu\"),\n",
        "                            layers.Dense(1, activation = \"linear\")\n",
        "])\n",
        "\n",
        "model_6.compile(loss=\"mae\", optimizer=keras.optimizers.Adam(learning_rate=.001))\n",
        "\n",
        "model_6_history = model_6.fit(X_train, y_train, epochs = 150, validation_data = (X_val, y_val), \n",
        "                              callbacks = [cf.create_model_checkpoint(\"model_6\")], batch_size=128)\n",
        "\n",
        "model_6.load_weights(\"model_experiments/model_6\")\n",
        "\n",
        "model_6_results = cf.evaluate_time_series(y_val, tf.squeeze(model_6.predict(X_val)))\n",
        "cf.plot_loss_curves(model_6_history, plot_accuracy=False)\n",
        "cf.plot_time_series(bitcoin_prices_df.index[-len(y_val):], y_val, format = '-', label = \"actual\", start=450)\n",
        "cf.plot_time_series(bitcoin_prices_df.index[-len(y_val):], model_6.predict(X_val), format = '-', label = \"predicted\", start=450)"
      ],
      "metadata": {
        "id": "BFGOwqEd8xrS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f741cdc8-1ea9-44da-c95d-6de527f7dd90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "18/18 [==============================] - 1s 11ms/step - loss: 2006.2863 - val_loss: 1980.5645\n",
            "Epoch 2/150\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 366.0823 - val_loss: 1873.8966\n",
            "Epoch 3/150\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 232.2570 - val_loss: 1449.2363\n",
            "Epoch 4/150\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 201.2239 - val_loss: 1074.7090\n",
            "Epoch 5/150\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 190.8322 - val_loss: 1035.7725\n",
            "Epoch 6/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 179.2048 - val_loss: 997.9075\n",
            "Epoch 7/150\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 171.9150 - val_loss: 967.7928\n",
            "Epoch 8/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 161.5332 - val_loss: 884.0356\n",
            "Epoch 9/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 152.0124 - val_loss: 884.7833\n",
            "Epoch 10/150\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 144.3619 - val_loss: 801.2128\n",
            "Epoch 11/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 140.1497 - val_loss: 773.6666\n",
            "Epoch 12/150\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 136.8504 - val_loss: 726.6115\n",
            "Epoch 13/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 131.1680 - val_loss: 751.4651\n",
            "Epoch 14/150\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 131.4208 - val_loss: 688.6005\n",
            "Epoch 15/150\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 127.2549 - val_loss: 752.9991\n",
            "Epoch 16/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 127.3583 - val_loss: 747.9217\n",
            "Epoch 17/150\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 121.1961 - val_loss: 669.5640\n",
            "Epoch 18/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 120.8669 - val_loss: 941.6265\n",
            "Epoch 19/150\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 137.0535 - val_loss: 640.1378\n",
            "Epoch 20/150\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 128.0912 - val_loss: 624.0293\n",
            "Epoch 21/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 116.1945 - val_loss: 632.1524\n",
            "Epoch 22/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 113.0624 - val_loss: 724.4630\n",
            "Epoch 23/150\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 118.6148 - val_loss: 615.7095\n",
            "Epoch 24/150\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 113.8009 - val_loss: 613.4769\n",
            "Epoch 25/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 114.5993 - val_loss: 634.3680\n",
            "Epoch 26/150\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 116.6054 - val_loss: 608.2533\n",
            "Epoch 27/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 123.8122 - val_loss: 618.0568\n",
            "Epoch 28/150\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 111.6949 - val_loss: 607.5242\n",
            "Epoch 29/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 111.4126 - val_loss: 666.0856\n",
            "Epoch 30/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 115.3751 - val_loss: 681.3027\n",
            "Epoch 31/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 122.8461 - val_loss: 708.4883\n",
            "Epoch 32/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 117.8372 - val_loss: 651.6206\n",
            "Epoch 33/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 114.1625 - val_loss: 621.4503\n",
            "Epoch 34/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 111.6257 - val_loss: 634.5078\n",
            "Epoch 35/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 117.1026 - val_loss: 631.6183\n",
            "Epoch 36/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 116.3463 - val_loss: 594.6478\n",
            "Epoch 37/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 110.8348 - val_loss: 708.9122\n",
            "Epoch 38/150\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 119.1145 - val_loss: 676.2973\n",
            "Epoch 39/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 111.4460 - val_loss: 601.7462\n",
            "Epoch 40/150\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 110.9078 - val_loss: 586.8400\n",
            "Epoch 41/150\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 111.3689 - val_loss: 686.9055\n",
            "Epoch 42/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 108.5584 - val_loss: 599.5547\n",
            "Epoch 43/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 109.2122 - val_loss: 607.6333\n",
            "Epoch 44/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 124.0028 - val_loss: 684.8885\n",
            "Epoch 45/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 113.6732 - val_loss: 591.3864\n",
            "Epoch 46/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 110.4802 - val_loss: 594.7916\n",
            "Epoch 47/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 108.1120 - val_loss: 636.9759\n",
            "Epoch 48/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 108.3736 - val_loss: 590.0306\n",
            "Epoch 49/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 110.0169 - val_loss: 644.7031\n",
            "Epoch 50/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 115.6360 - val_loss: 643.8494\n",
            "Epoch 51/150\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 113.3977 - val_loss: 579.2696\n",
            "Epoch 52/150\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 107.5623 - val_loss: 580.3340\n",
            "Epoch 53/150\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 106.2059 - val_loss: 584.3944\n",
            "Epoch 54/150\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 106.5480 - val_loss: 602.0848\n",
            "Epoch 55/150\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 105.5507 - val_loss: 613.6648\n",
            "Epoch 56/150\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 108.0581 - val_loss: 677.4175\n",
            "Epoch 57/150\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 109.8940 - val_loss: 600.3657\n",
            "Epoch 58/150\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 110.3647 - val_loss: 578.0416\n",
            "Epoch 59/150\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 111.5895 - val_loss: 577.8093\n",
            "Epoch 60/150\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 105.4039 - val_loss: 584.7873\n",
            "Epoch 61/150\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 105.6120 - val_loss: 613.3488\n",
            "Epoch 62/150\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 107.5964 - val_loss: 667.8401\n",
            "Epoch 63/150\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 122.9667 - val_loss: 576.8683\n",
            "Epoch 64/150\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 114.0435 - val_loss: 638.1574\n",
            "Epoch 65/150\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 111.8724 - val_loss: 602.3884\n",
            "Epoch 66/150\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 108.6861 - val_loss: 620.4289\n",
            "Epoch 67/150\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 108.1143 - val_loss: 600.7676\n",
            "Epoch 68/150\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 108.3230 - val_loss: 643.5097\n",
            "Epoch 69/150\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 107.7162 - val_loss: 600.3680\n",
            "Epoch 70/150\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 113.2957 - val_loss: 578.9000\n",
            "Epoch 71/150\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 109.8110 - val_loss: 611.6907\n",
            "Epoch 72/150\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 109.0766 - val_loss: 584.7855\n",
            "Epoch 73/150\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 107.3010 - val_loss: 585.9331\n",
            "Epoch 74/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 109.7765 - val_loss: 590.0876\n",
            "Epoch 75/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 119.3685 - val_loss: 878.6222\n",
            "Epoch 76/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 117.7709 - val_loss: 630.5481\n",
            "Epoch 77/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 116.1629 - val_loss: 615.9470\n",
            "Epoch 78/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 104.7989 - val_loss: 577.3239\n",
            "Epoch 79/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 113.0682 - val_loss: 650.3467\n",
            "Epoch 80/150\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 109.5927 - val_loss: 577.1078\n",
            "Epoch 81/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 112.7816 - val_loss: 746.3208\n",
            "Epoch 82/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 113.2668 - val_loss: 665.0609\n",
            "Epoch 83/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 105.9537 - val_loss: 578.1309\n",
            "Epoch 84/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 105.8261 - val_loss: 582.4112\n",
            "Epoch 85/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 108.5562 - val_loss: 597.9417\n",
            "Epoch 86/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 108.4146 - val_loss: 582.5422\n",
            "Epoch 87/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 104.7568 - val_loss: 581.1352\n",
            "Epoch 88/150\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 106.2695 - val_loss: 714.5063\n",
            "Epoch 89/150\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 106.5837 - val_loss: 632.9106\n",
            "Epoch 90/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 107.9535 - val_loss: 596.0231\n",
            "Epoch 91/150\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 107.1042 - val_loss: 694.7618\n",
            "Epoch 92/150\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 107.2856 - val_loss: 576.0916\n",
            "Epoch 93/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 106.2315 - val_loss: 576.9521\n",
            "Epoch 94/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 105.7881 - val_loss: 582.6526\n",
            "Epoch 95/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 108.0175 - val_loss: 662.9094\n",
            "Epoch 96/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 118.2189 - val_loss: 648.8604\n",
            "Epoch 97/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 108.4649 - val_loss: 579.6887\n",
            "Epoch 98/150\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 108.8378 - val_loss: 603.6293\n",
            "Epoch 99/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 105.1165 - val_loss: 605.9889\n",
            "Epoch 100/150\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 104.7740 - val_loss: 676.6475\n",
            "Epoch 101/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 116.3551 - val_loss: 589.2601\n",
            "Epoch 102/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 107.2730 - val_loss: 576.1140\n",
            "Epoch 103/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 109.0531 - val_loss: 577.9075\n",
            "Epoch 104/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 106.4575 - val_loss: 635.3976\n",
            "Epoch 105/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 120.5948 - val_loss: 578.1116\n",
            "Epoch 106/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 110.3419 - val_loss: 574.5958\n",
            "Epoch 107/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 106.9355 - val_loss: 586.4651\n",
            "Epoch 108/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 105.6266 - val_loss: 585.4226\n",
            "Epoch 109/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 104.4098 - val_loss: 619.4713\n",
            "Epoch 110/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 108.3858 - val_loss: 695.0032\n",
            "Epoch 111/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 112.6059 - val_loss: 579.7602\n",
            "Epoch 112/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 108.7091 - val_loss: 592.7938\n",
            "Epoch 113/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 105.8831 - val_loss: 640.6630\n",
            "Epoch 114/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 106.5922 - val_loss: 753.7796\n",
            "Epoch 115/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 113.8926 - val_loss: 605.7734\n",
            "Epoch 116/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 108.1320 - val_loss: 666.6133\n",
            "Epoch 117/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 110.2031 - val_loss: 609.2076\n",
            "Epoch 118/150\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 105.9571 - val_loss: 594.2131\n",
            "Epoch 119/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 104.9086 - val_loss: 597.5620\n",
            "Epoch 120/150\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 112.9443 - val_loss: 606.2943\n",
            "Epoch 121/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 111.4021 - val_loss: 605.3467\n",
            "Epoch 122/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 107.9510 - val_loss: 578.3969\n",
            "Epoch 123/150\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 105.5186 - val_loss: 598.0099\n",
            "Epoch 124/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 107.9621 - val_loss: 585.4396\n",
            "Epoch 125/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 108.4284 - val_loss: 583.4892\n",
            "Epoch 126/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 106.2016 - val_loss: 671.7792\n",
            "Epoch 127/150\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 115.5855 - val_loss: 729.8705\n",
            "Epoch 128/150\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 110.4554 - val_loss: 617.2437\n",
            "Epoch 129/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 104.9800 - val_loss: 583.3561\n",
            "Epoch 130/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 103.7228 - val_loss: 576.6004\n",
            "Epoch 131/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 105.1960 - val_loss: 623.0606\n",
            "Epoch 132/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 108.4336 - val_loss: 576.5273\n",
            "Epoch 133/150\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 103.1622 - val_loss: 580.3602\n",
            "Epoch 134/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 103.4232 - val_loss: 578.5934\n",
            "Epoch 135/150\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 106.5116 - val_loss: 578.7743\n",
            "Epoch 136/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 122.3209 - val_loss: 742.5909\n",
            "Epoch 137/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 105.7559 - val_loss: 603.8425\n",
            "Epoch 138/150\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 106.2976 - val_loss: 579.4894\n",
            "Epoch 139/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 105.2481 - val_loss: 650.4420\n",
            "Epoch 140/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 108.4119 - val_loss: 682.0440\n",
            "Epoch 141/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 123.4911 - val_loss: 720.6841\n",
            "Epoch 142/150\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 120.1658 - val_loss: 840.6577\n",
            "Epoch 143/150\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 117.5448 - val_loss: 595.1406\n",
            "Epoch 144/150\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 109.1732 - val_loss: 600.6473\n",
            "Epoch 145/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 108.5597 - val_loss: 593.5917\n",
            "Epoch 146/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 106.2041 - val_loss: 637.9698\n",
            "Epoch 147/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 105.8454 - val_loss: 581.2294\n",
            "Epoch 148/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 103.6707 - val_loss: 590.8052\n",
            "Epoch 149/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 104.3348 - val_loss: 583.0645\n",
            "Epoch 150/150\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 105.2792 - val_loss: 580.2897\n",
            "Error in callback <function install_repl_displayhook.<locals>.post_execute at 0x7fc85c9d78c0> (for post_execute):\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mpost_execute\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mpost_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_interactive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                     \u001b[0mdraw_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;31m# IPython >= 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/_pylab_helpers.py\u001b[0m in \u001b[0;36mdraw_all\u001b[0;34m(cls, force)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mf_mgr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_fig_managers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mforce\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mf_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                 \u001b[0mf_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0matexit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroy_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mdraw_idle\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1945\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_idle_drawing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1946\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_idle_draw_cntx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1947\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1949\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"3.2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    391\u001b[0m              (self.toolbar._wait_cursor_for_draw_cm() if self.toolbar\n\u001b[1;32m    392\u001b[0m               else nullcontext()):\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m             \u001b[0;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0;31m# don't forget to call the superclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1736\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2628\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2630\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2632\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1225\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1227\u001b[0;31m         \u001b[0mticks_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1228\u001b[0m         ticklabelBoxes, ticklabelBoxes2 = self._get_tick_bboxes(ticks_to_draw,\n\u001b[1;32m   1229\u001b[0m                                                                 renderer)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_update_ticks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1101\u001b[0m         \u001b[0mthe\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mReturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mticks\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mdrawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \"\"\"\n\u001b[0;32m-> 1103\u001b[0;31m         \u001b[0mmajor_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_majorticklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m         \u001b[0mmajor_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajor_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m         \u001b[0mmajor_ticks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_major_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajor_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_majorticklocs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1346\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_majorticklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m         \u001b[0;34m\"\"\"Get the array of major tick locations in data coordinates.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_minorticklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/dates.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1336\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m         \u001b[0;34m'Return the locations of the ticks'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1338\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1339\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_locator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/dates.py\u001b[0m in \u001b[0;36mrefresh\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m         \u001b[0;31m# docstring inherited\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1364\u001b[0;31m         \u001b[0mdmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewlim_to_dt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1365\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_locator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_locator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/dates.py\u001b[0m in \u001b[0;36mviewlim_to_dt\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                              \u001b[0;34m'often happens if you pass a non-datetime '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m                              \u001b[0;34m'value to an axis that has datetime units'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m                              .format(vmin))\n\u001b[0m\u001b[1;32m   1099\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnum2date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum2date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: view limit minimum -36896.4 is less than 1 and is an invalid Matplotlib date value. This often happens if you pass a non-datetime value to an axis that has datetime units"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     37\u001b[0m             display(\n\u001b[1;32m     38\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             )\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36m_fetch_figure_metadata\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;31m# the background is transparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         ticksLight = _is_light([label.get_color()\n\u001b[0;32m--> 177\u001b[0;31m                                 \u001b[0;32mfor\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m                                 \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                                 for label in axis.get_ticklabels()])\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    177\u001b[0m                                 \u001b[0;32mfor\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                                 \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                                 for label in axis.get_ticklabels()])\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mticksLight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mticksLight\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mticksLight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;31m# there are one or more tick labels, all with the same lightness\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_ticklabels\u001b[0;34m(self, minor, which)\u001b[0m\n\u001b[1;32m   1318\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mminor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_minorticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_majorticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_majorticklines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_majorticklabels\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1274\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_majorticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m         \u001b[0;34m'Return a list of Text instances for the major ticklabels.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1276\u001b[0;31m         \u001b[0mticks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_major_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1277\u001b[0m         \u001b[0mlabels1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtick\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mticks\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m         \u001b[0mlabels2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtick\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mticks\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_major_ticks\u001b[0;34m(self, numticks)\u001b[0m\n\u001b[1;32m   1429\u001b[0m         \u001b[0;34m'Get the tick instances; grow as necessary.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumticks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1431\u001b[0;31m             \u001b[0mnumticks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_majorticklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajorTicks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnumticks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_majorticklocs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1346\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_majorticklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m         \u001b[0;34m\"\"\"Get the array of major tick locations in data coordinates.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_minorticklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/dates.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1336\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m         \u001b[0;34m'Return the locations of the ticks'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1338\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1339\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_locator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/dates.py\u001b[0m in \u001b[0;36mrefresh\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m         \u001b[0;31m# docstring inherited\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1364\u001b[0;31m         \u001b[0mdmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewlim_to_dt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1365\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_locator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_locator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/dates.py\u001b[0m in \u001b[0;36mviewlim_to_dt\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                              \u001b[0;34m'often happens if you pass a non-datetime '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m                              \u001b[0;34m'value to an axis that has datetime units'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m                              .format(vmin))\n\u001b[0m\u001b[1;32m   1099\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnum2date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum2date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: view limit minimum -36896.4 is less than 1 and is an invalid Matplotlib date value. This often happens if you pass a non-datetime value to an axis that has datetime units"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating N-BEATS block layers"
      ],
      "metadata": {
        "id": "wG8B5U3BORSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NBeatsBlock(layers.Layer):\n",
        "  def __init__(self,\n",
        "               input_size: int,\n",
        "               theta_size: int,\n",
        "               horizon: int,\n",
        "               n_neurons: int,\n",
        "               n_layers: int,\n",
        "               **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.input_size = input_size\n",
        "    self.theta_size = theta_size\n",
        "    self.horizon = horizon\n",
        "    self.n_neurons = n_neurons\n",
        "    self.n_layers = n_layers\n",
        "\n",
        "    self.hidden = [layers.Dense(n_neurons, activation=\"relu\") for _ in range(n_layers)]\n",
        "    self.theta_layer = layers.Dense(theta_size, activation=\"linear\", name=\"theta_layer\")\n",
        "\n",
        "  def call(self, inputs):\n",
        "    x = inputs\n",
        "    for layer in self.hidden:\n",
        "      x = layer(x)\n",
        "    theta = self.theta_layer(x)\n",
        "    backcast, forecast = theta[:, :self.input_size], theta[:, -self.horizon]\n",
        "    return backcast, forecast"
      ],
      "metadata": {
        "id": "8tDCyWtwOVLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing data pipelines"
      ],
      "metadata": {
        "id": "yk-OIvdvditV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "univariate_df = multivariate_df.drop(\"block_reward\", axis=1)\n",
        "y = univariate_df[\"price\"].astype(np.float32)\n",
        "X = univariate_df.drop(\"price\", axis=1).astype(np.float32)\n",
        "X_train, y_train, X_val, y_val = X[:split_size], y[:split_size], X[split_size:], y[split_size:]\n",
        "\n",
        "train_features_ds = tf.data.Dataset.from_tensor_slices(X_train)\n",
        "train_labels_ds = tf.data.Dataset.from_tensor_slices(y_train)\n",
        "\n",
        "val_features_ds = tf.data.Dataset.from_tensor_slices(X_val)\n",
        "val_labels_ds = tf.data.Dataset.from_tensor_slices(y_val)\n",
        "\n",
        "train_ds = tf.data.Dataset.zip((train_features_ds, train_labels_ds))\n",
        "val_ds = tf.data.Dataset.zip((val_features_ds,val_labels_ds))\n",
        "\n",
        "train_ds=train_ds.batch(1024).prefetch(tf.data.AUTOTUNE)\n",
        "val_ds=val_ds.batch(1024).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "tVr-6sl5dmdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 7 B-BEATS W=7 H+1"
      ],
      "metadata": {
        "id": "vpT27NWYgAi-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "WINDOW_SIZE = 7\n",
        "HORIZON = 1\n",
        "# hyper paremters \n",
        "\n",
        "N_EPOCHS = 5000\n",
        "N_NUERONS = 512\n",
        "N_LAYERS = 4\n",
        "N_STACKS = 30\n",
        "\n",
        "INPUT_SIZE = WINDOW_SIZE * HORIZON\n",
        "THETA_SIZE = INPUT_SIZE + HORIZON"
      ],
      "metadata": {
        "id": "rinyjuTPgDh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Nbeats_layer = NBeatsBlock(input_size = INPUT_SIZE, theta_size = THETA_SIZE, horizon = HORIZON,\n",
        "                           n_neurons = N_NUERONS, n_layers = N_LAYERS, name=\"inital_stack_layer\") \n",
        "tf.random.set_seed(42)\n",
        "\n",
        "stack_input = layers.Input(shape=(INPUT_SIZE), name=\"stack_input\")\n",
        "\n",
        "backcast_1 , forecast_1 = Nbeats_layer(stack_input)\n",
        "\n",
        "residuals = layers.Subtract()([stack_input,backcast_1])\n",
        "global_forecast = forecast_1\n",
        "\n",
        "for i, _ in enumerate(range(N_STACKS-1)):\n",
        "  backcast, block_forecast = NBeatsBlock(INPUT_SIZE, THETA_SIZE, HORIZON, N_NUERONS, N_LAYERS, name=f\"Nbeats_block{i+1}\") (residuals)\n",
        "  residuals = layers.Subtract()([residuals, backcast])\n",
        "  global_forecast = layers.Add()([global_forecast, block_forecast])\n",
        "\n",
        "model_7 = keras.Model(inputs = stack_input, outputs = global_forecast)\n",
        "keras.utils.plot_model(model_7, show_shapes = True)\n",
        "\n",
        "model_7.compile(loss=\"mae\", optimizer = \"Adam\")\n",
        "\n",
        "model_7_history = model_7.fit(train_ds, epochs = N_EPOCHS, validation_data=val_ds, \n",
        "            callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=100, restore_best_weights=True),\n",
        "                         keras.callbacks.ReduceLROnPlateau(pateince = 50, factor=0.1, monitor = \"val_loss\", verbose = 1)])"
      ],
      "metadata": {
        "id": "4w89oIppi089"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_7_results = cf.evaluate_time_series(y_val, model_7.predict(val_ds))\n",
        "model_7_results\n",
        "cf.plot_loss_curves(model_7_history, plot_accuracy = False)\n",
        "cf.plot_time_series(bitcoin_prices_df.index[-len(y_val):], y_val, format = '-', label = \"actual\", start=450)\n",
        "cf.plot_time_series(bitcoin_prices_df.index[-len(y_val):], model_7.predict(val_ds), format = '-', label = \"predicted\", start=450)"
      ],
      "metadata": {
        "id": "BxhM7xpyExLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 8 ensemble"
      ],
      "metadata": {
        "id": "zEV1MCNhEozI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ensemble_model(horizon, train_ds, val_ds, num_iter, num_epochs, loss_fun):\n",
        "  \n",
        "  ensemble_models=[]\n",
        "\n",
        "  for i in range(num_iter):\n",
        "    for loss_function in loss_fun:\n",
        "      print(f\"Model{i} with loss {loss_function} for {num_epochs} epochs\")\n",
        "      model = tf.keras.Sequential([\n",
        "              layers.Dense(128, kernel_initializer=\"he_normal\", activation=\"relu\"),\n",
        "              layers.Dense(128, kernel_initializer=\"he_normal\", activation=\"relu\"),\n",
        "              layers.Dense(horizon)\n",
        "      ])\n",
        "\n",
        "      model.compile(loss=loss_function,\n",
        "                    optimizer = \"Adam\",\n",
        "                    metrics = [\"mae\", \"mse\"])\n",
        "      model.fit(train_ds, epochs = num_epochs, validation_data = val_ds, verbose = 0,\n",
        "                callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=200, restore_best_weights=True),\n",
        "                          keras.callbacks.ReduceLROnPlateau(pateince = 100, factor=0.1, monitor = \"val_loss\", verbose = 0)])\n",
        "      \n",
        "      ensemble_models.append(model)\n",
        "  \n",
        "  return ensemble_models\n",
        "\n",
        "def make_ensemble_preds(ensemble_models, val_ds):\n",
        "  ensemble_preds = []\n",
        "  for model in ensemble_models:\n",
        "    ensemble_preds.append(model.predict(val_ds))\n",
        "  return ensemble_preds\n",
        "\n",
        "def get_lower_upper(preds):\n",
        "  std = tf.math.reduce_std(preds, axis=0)\n",
        "  interval = 1.96 * std\n",
        "  mean = tf.reduce_mean(preds, axis=0)\n",
        "  lower = mean - interval\n",
        "  upper = mean + interval\n",
        "  return lower, upper\n"
      ],
      "metadata": {
        "id": "4TCiFTMYEubg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_models = get_ensemble_model(1, train_ds, val_ds, 5, 1000, loss_fun=[\"mae\", \"mse\", \"mape\"])\n",
        "\n",
        "ensemble_preds = tf.squeeze(np.array(make_ensemble_preds(ensemble_models, val_ds)))\n",
        "lower ,upper = get_lower_upper(ensemble_preds)\n",
        "ensemble_preds = np.median(ensemble_preds, axis=0)\n",
        "\n",
        "ensemble_model_results = cf.evaluate_time_series(y_val, ensemble_preds)\n",
        "\n",
        "cf.plot_time_series( bitcoin_prices_df.index[-len(y_val):], lower ,format = \"-\", start=450)\n",
        "cf.plot_time_series( bitcoin_prices_df.index[-len(y_val):], upper , format = \"-\", start=450)\n",
        "\n",
        "plt.fill_between(X_val.index[-450:], lower[-450:], upper[-450:], label=\"pridcition_Interval\")"
      ],
      "metadata": {
        "id": "eDqHRo_OKZY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model 9 into the future"
      ],
      "metadata": {
        "id": "NWxCt3v07O2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = multivariate_df[\"price\"].to_numpy()\n",
        "X = multivariate_df.drop(\"price\", axis=1).astype(np.float32)\n",
        "\n",
        "X_ds = tf.data.Dataset.from_tensor_slices(tf.cast(X, dtype=tf.float32)) \n",
        "y_ds = tf.data.Dataset.from_tensor_slices(tf.cast(y, dtype=tf.float32))\n",
        "\n",
        "all_ds = tf.data.Dataset.zip((X_ds, y_ds))\n",
        "all_ds = all_ds.batch(1024).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "RqPvBnkQ7UZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "model_9 = keras.Sequential([\n",
        "          layers.Dense(128, activation=\"relu\"),\n",
        "          layers.Dense(128, activation=\"relu\"),\n",
        "          layers.Dense(1, activation=\"linear\")                            \n",
        "])\n",
        "\n",
        "model_9.compile( loss=\"mae\", optimizer = \"Adam\")\n",
        "\n",
        "model_9_history = model_9.fit(all_ds, epochs=100, verbose =0)\n",
        "\n",
        "cf.plot_loss_curves(model_9_history, plot_accuracy=False, only_training_data = True)"
      ],
      "metadata": {
        "id": "bDpPpxWDAbUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "def predict_into_future(model, days, X):\n",
        "  horizon = tf.squeeze(model_9.predict(X))[-1].numpy()\n",
        "  predictions = [horizon]\n",
        "  for _ in range(days-1):\n",
        "\n",
        "    br = X[\"block_reward\"][-1]\n",
        "    p1 = X[\"price2\"][-1]\n",
        "    p2 = X[\"price3\"][-1]\n",
        "    p3 = X[\"price4\"][-1]\n",
        "    p4 = X[\"price5\"][-1]\n",
        "    p5 = X[\"price6\"][-1]\n",
        "    p6 = X[\"price7\"][-1] \n",
        "    p7 = horizon              \n",
        "  \n",
        "    row = pd.DataFrame(\n",
        "      {'Date': (X.index[-1]), 'block_reward':br, 'price1': p1, 'price2': p2 , \n",
        "       'price2': p3, 'price3': p4, 'price4': p4, 'price5': p5, 'price6': p6, 'price7': p7},\n",
        "       index = [\"Date\"])\n",
        "    X = X.append(row)\n",
        "\n",
        "    horizon = tf.squeeze(model.predict( np.array( [[[br,p1,p2,p3,p4,p5,p6,p7]]] ) )).numpy()\n",
        "    predictions.append(horizon)\n",
        "  \n",
        "  return np.array(predictions), X"
      ],
      "metadata": {
        "id": "n4hPJKffBzTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "future_predictions, X = predict_into_future(model_9, 100, X)\n",
        "cf.plot_time_series(np.arange(len(y)+len(future_predictions)), np.concatenate((y,future_predictions),axis=0), format=\"-\")\n",
        "X.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YyxlOgneGeFY",
        "outputId": "57488095-af80-443a-c262-5ccc9dced00e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     block_reward      price1      price2      price3  \\\n",
              "2013-10-08 00:00:00          25.0  121.794998  120.655327  121.338661   \n",
              "2013-10-09 00:00:00          25.0  123.032997  121.794998  120.655327   \n",
              "2013-10-10 00:00:00          25.0  124.049004  123.032997  121.794998   \n",
              "2013-10-11 00:00:00          25.0  125.961159  124.049004  123.032997   \n",
              "2013-10-12 00:00:00          25.0  125.279663  125.961159  124.049004   \n",
              "\n",
              "                         price4      price5      price6      price7 Date  \n",
              "2013-10-08 00:00:00  118.674660  108.584831  125.455002  123.654991  NaT  \n",
              "2013-10-09 00:00:00  121.338661  118.674660  108.584831  125.455002  NaT  \n",
              "2013-10-10 00:00:00  120.655327  121.338661  118.674660  108.584831  NaT  \n",
              "2013-10-11 00:00:00  121.794998  120.655327  121.338661  118.674660  NaT  \n",
              "2013-10-12 00:00:00  123.032997  121.794998  120.655327  121.338661  NaT  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e33f36e2-a7af-45d9-aefa-05d2679334e3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>block_reward</th>\n",
              "      <th>price1</th>\n",
              "      <th>price2</th>\n",
              "      <th>price3</th>\n",
              "      <th>price4</th>\n",
              "      <th>price5</th>\n",
              "      <th>price6</th>\n",
              "      <th>price7</th>\n",
              "      <th>Date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-10-08 00:00:00</th>\n",
              "      <td>25.0</td>\n",
              "      <td>121.794998</td>\n",
              "      <td>120.655327</td>\n",
              "      <td>121.338661</td>\n",
              "      <td>118.674660</td>\n",
              "      <td>108.584831</td>\n",
              "      <td>125.455002</td>\n",
              "      <td>123.654991</td>\n",
              "      <td>NaT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-09 00:00:00</th>\n",
              "      <td>25.0</td>\n",
              "      <td>123.032997</td>\n",
              "      <td>121.794998</td>\n",
              "      <td>120.655327</td>\n",
              "      <td>121.338661</td>\n",
              "      <td>118.674660</td>\n",
              "      <td>108.584831</td>\n",
              "      <td>125.455002</td>\n",
              "      <td>NaT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-10 00:00:00</th>\n",
              "      <td>25.0</td>\n",
              "      <td>124.049004</td>\n",
              "      <td>123.032997</td>\n",
              "      <td>121.794998</td>\n",
              "      <td>120.655327</td>\n",
              "      <td>121.338661</td>\n",
              "      <td>118.674660</td>\n",
              "      <td>108.584831</td>\n",
              "      <td>NaT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-11 00:00:00</th>\n",
              "      <td>25.0</td>\n",
              "      <td>125.961159</td>\n",
              "      <td>124.049004</td>\n",
              "      <td>123.032997</td>\n",
              "      <td>121.794998</td>\n",
              "      <td>120.655327</td>\n",
              "      <td>121.338661</td>\n",
              "      <td>118.674660</td>\n",
              "      <td>NaT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-12 00:00:00</th>\n",
              "      <td>25.0</td>\n",
              "      <td>125.279663</td>\n",
              "      <td>125.961159</td>\n",
              "      <td>124.049004</td>\n",
              "      <td>123.032997</td>\n",
              "      <td>121.794998</td>\n",
              "      <td>120.655327</td>\n",
              "      <td>121.338661</td>\n",
              "      <td>NaT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e33f36e2-a7af-45d9-aefa-05d2679334e3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e33f36e2-a7af-45d9-aefa-05d2679334e3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e33f36e2-a7af-45d9-aefa-05d2679334e3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 205
        }
      ]
    }
  ]
}